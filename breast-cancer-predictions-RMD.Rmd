---
title: "560 - Project 2"
author: "Steven Hahn"
date: "5/19/2021"
output: word_document
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

####Business Understanding####
#The data for this project comes from clinical samples of breast cancer from the University of Wisconsin Hospitals between January 1989 and November 1991. Sample collection and analysis was performed in batches by Dr. WIlliam H. Wolberg. 
#The purpose of this project is to develop multiple classification methods to classify breast cancer tumors as benign or malignant. Overall classification will be done via an ensemble fashion; the various classifiers will each make a prediction and the overall classification will be determined by majority rule. 
#Source: https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original) 

```{r}
#Install and library packages
#install.packages("mlbench")
library(mlbench)

#Load data
data(BreastCancer)
BreastCancer.df <- BreastCancer

#Remove rows with missing values 
BreastCancer.df <- na.omit(BreastCancer.df) 
```

####Data Understanding Phase####
#In this phase, we will review the overal strucutre of the dataset. This review will be done using summarization methods as well as visualizations. 

```{r}
#Review and describe the basic structure of the data
str(BreastCancer.df)
summary(BreastCancer.df)


```

```{r}
#graph variables 

library(ggplot2)
ggplot(BreastCancer.df) + geom_bar(aes(x = Cl.thickness))
ggplot(BreastCancer.df) + geom_bar(aes(x = Cell.size))
ggplot(BreastCancer.df) + geom_bar(aes(x = Cell.shape))
ggplot(BreastCancer.df) + geom_bar(aes(x = Marg.adhesion))
ggplot(BreastCancer.df) + geom_bar(aes(x = Epith.c.size))
ggplot(BreastCancer.df) + geom_bar(aes(x = Bare.nuclei))
ggplot(BreastCancer.df) + geom_bar(aes(x = Bl.cromatin))
ggplot(BreastCancer.df) + geom_bar(aes(x = Normal.nucleoli))
ggplot(BreastCancer.df) + geom_bar(aes(x = Mitoses))

```

```{r}
#Graph variables with our lable, Class, to get a clearer understanding of how each variable relates to our label. For each variable, there are two plots. The first is a simple count of the Class compared to the varaible; the second shows the Class as a percentage of each factor of the varialbe. 

#Plot Cell Thickness vs. Class
ggplot() +
  geom_bar(data = BreastCancer.df,
           aes(x = factor(Cl.thickness),
               fill = factor(Class)),
           position = "stack") +
  scale_x_discrete("Cell Thickness") +
  scale_y_continuous("Percent") +
  guides(fill=guide_legend(title="Class"))+
  scale_fill_manual(values=c("blue",
                             "red"))
ggplot() +
  geom_bar(data=BreastCancer.df,
           aes(x = factor(Cl.thickness),
               fill = factor(Class)),
           position = "fill") +
  scale_x_discrete("Cell Thickness")+
  scale_y_continuous("Percent") +
  guides(fill=guide_legend(title="Class")) +
  scale_fill_manual(values=c("blue", "red"))

```

```{r}
#Plot Cell.size vs. Class
ggplot() +
  geom_bar(data = BreastCancer.df,
           aes(x = factor(Cell.size),
               fill = factor(BreastCancer.df$Class)),
           position = "stack") +
  scale_x_discrete("Cell Size") +
  scale_y_continuous("Percent") +
  guides(fill=guide_legend(title="Class"))+
  scale_fill_manual(values=c("blue",
                             "red"))
ggplot() +
  geom_bar(data=BreastCancer.df,
           aes(x = factor(Cell.size),
               fill = factor(BreastCancer.df$Class)),
           position = "fill") +
  scale_x_discrete("Cell Size")+
  scale_y_continuous("Percent") +
  guides(fill=guide_legend(title="Class")) +
  scale_fill_manual(values=c("blue", "red"))
```

```{r}
#Plot Cell.shape vs. Class
ggplot() +
  geom_bar(data = BreastCancer.df,
           aes(x = factor(Cell.shape),
               fill = factor(BreastCancer.df$Class)),
           position = "stack") +
  scale_x_discrete("Cell Shape") +
  scale_y_continuous("Percent") +
  guides(fill=guide_legend(title="Class"))+
  scale_fill_manual(values=c("blue",
                             "red"))
ggplot() +
  geom_bar(data=BreastCancer.df,
           aes(x = factor(Cell.shape),
               fill = factor(BreastCancer.df$Class)),
           position = "fill") +
  scale_x_discrete("Cell Shape")+
  scale_y_continuous("Percent") +
  guides(fill=guide_legend(title="Class")) +
  scale_fill_manual(values=c("blue", "red"))
```

```{r}
#Plot Marg.adhesion vs. Class
ggplot() +
  geom_bar(data = BreastCancer.df,
           aes(x = factor(Marg.adhesion),
               fill = factor(BreastCancer.df$Class)),
           position = "stack") +
  scale_x_discrete("Marg.adhesion") +
  scale_y_continuous("Percent") +
  guides(fill=guide_legend(title="Class"))+
  scale_fill_manual(values=c("blue",
                             "red"))
ggplot() +
  geom_bar(data=BreastCancer.df,
           aes(x = factor(Marg.adhesion),
               fill = factor(BreastCancer.df$Class)),
           position = "fill") +
  scale_x_discrete("Marg.adhesion")+
  scale_y_continuous("Percent") +
  guides(fill=guide_legend(title="Class")) +
  scale_fill_manual(values=c("blue", "red"))
```

```{r}
#Plot Bare nuclei vs. Class
ggplot() +
  geom_bar(data = BreastCancer.df,
           aes(x = factor(Bare.nuclei),
               fill = factor(BreastCancer.df$Class)),
           position = "stack") +
  scale_x_discrete("Bare.nuclei") +
  scale_y_continuous("Percent") +
  guides(fill=guide_legend(title="Class"))+
  scale_fill_manual(values=c("blue",
                             "red"))
ggplot() +
  geom_bar(data=BreastCancer.df,
           aes(x = factor(Bare.nuclei),
               fill = factor(BreastCancer.df$Class)),
           position = "fill") +
  scale_x_discrete("Bare.nuclei")+
  scale_y_continuous("Percent") +
  guides(fill=guide_legend(title="Class")) +
  scale_fill_manual(values=c("blue", "red"))
```

```{r}
#Plot Bl.cromatin vs. Class
ggplot() +
  geom_bar(data = BreastCancer.df,
           aes(x = factor(Bl.cromatin),
               fill = factor(BreastCancer.df$Class)),
           position = "stack") +
  scale_x_discrete("Bl.cromatin") +
  scale_y_continuous("Percent") +
  guides(fill=guide_legend(title="Class"))+
  scale_fill_manual(values=c("blue",
                             "red"))
ggplot() +
  geom_bar(data=BreastCancer.df,
           aes(x = factor(Bl.cromatin),
               fill = factor(BreastCancer.df$Class)),
           position = "fill") +
  scale_x_discrete("Bl.cromatin")+
  scale_y_continuous("Percent") +
  guides(fill=guide_legend(title="Class")) +
  scale_fill_manual(values=c("blue", "red"))
```

```{r}
#Plot Normal.nucleoli vs. Class
ggplot() +
  geom_bar(data = BreastCancer.df,
           aes(x = factor(Normal.nucleoli),
               fill = factor(BreastCancer.df$Class)),
           position = "stack") +
  scale_x_discrete("Normal.nucleoli") +
  scale_y_continuous("Percent") +
  guides(fill=guide_legend(title="Class"))+
  scale_fill_manual(values=c("blue",
                             "red"))
ggplot() +
  geom_bar(data=BreastCancer.df,
           aes(x = factor(Normal.nucleoli),
               fill = factor(BreastCancer.df$Class)),
           position = "fill") +
  scale_x_discrete("Normal.nucleoli")+
  scale_y_continuous("Percent") +
  guides(fill=guide_legend(title="Class")) +
  scale_fill_manual(values=c("blue", "red"))
```

```{r}
#Plot Mitoses vs. Class
ggplot() +
  geom_bar(data = BreastCancer.df,
           aes(x = factor(Mitoses),
               fill = factor(BreastCancer.df$Class)),
           position = "stack") +
  scale_x_discrete("Mitoses") +
  scale_y_continuous("Percent") +
  guides(fill=guide_legend(title="Class"))+
  scale_fill_manual(values=c("blue",
                             "red"))
ggplot() +
  geom_bar(data=BreastCancer.df,
           aes(x = factor(Mitoses),
               fill = factor(BreastCancer.df$Class)),
           position = "fill") +
  scale_x_discrete("Mitoses")+
  scale_y_continuous("Percent") +
  guides(fill=guide_legend(title="Class")) +
  scale_fill_manual(values=c("blue", "red"))
```

```{r}
#Create correlation matrix 
corrdata <- cbind(BreastCancer.df$Cl.thickness, BreastCancer.df$Cell.size, BreastCancer.df$Cell.shape, BreastCancer.df$Marg.adhesion, BreastCancer.df$Epith.c.size, BreastCancer.df$Bare.nuclei, BreastCancer.df$Bl.cromatin, BreastCancer.df$Normal.nucleoli, BreastCancer.df$Mitoses)
corrdata

library(gplots)
heatmap.2(cor(corrdata), Rowv = FALSE, Colv = FALSE, dendrogram = "none", 
          cellnote = round(cor(corrdata),2), 
          notecol = "black", key = FALSE, trace = 'none', margins = c(2,2))

```

####Data Preparation Phase####
#As all variables are already scaled 1-10, we will not perform any standardization 
#Separate the data into training and validation set

```{r}
# remove the unique identifier, which is useless and would confuse the machine learning algorithms
BreastCancer.df$Id <- NULL 

# partition the data set for 80% training and 20% evaluation
train.index <- sample(c(1:dim(BreastCancer.df)[1]), dim(BreastCancer.df)[1]*0.8)  
train.df <- BreastCancer.df[train.index, ]
valid.df <- BreastCancer.df[-train.index, ]
```



####Modeling Phase####
#Develop and train models using the training data set. Then, use these models to predict the class of the validation data set. 
#The models will later be combined to provide a consolidated prediction based on majority rules.

```{r}
#01. Model using decision tree
library(rpart)
library(rpart.plot)
x.rp <- rpart(Class ~ ., data=train.df)
plot(x.rp, main="Decision tree created using rpart") 
prp(x.rp, type = 1, extra = 1, split.font = 1, varlen = -10)   
 

#prediction
# predict classes for the evaluation data set
x.rp.pred <- predict(x.rp, type="class", newdata=valid.df)  # to ensemble
# score the evaluation data set (extract the probabilities)
x.rp.prob <- predict(x.rp, type="prob", newdata=valid.df)
table(x.rp.pred,valid.df$Class) 
```

```{r}
#02. Model using Leave-1-Out Cross Validation (LOOCV)
ans <- numeric(nrow(BreastCancer.df))
for (i in 1:nrow(BreastCancer.df)) {
  mytree <- rpart(Class ~ ., BreastCancer.df[-i,])
  mytree.pred <- predict(mytree,BreastCancer.df[i,],type="class")
  ans[i] <- mytree.pred
}
ans <- factor(ans,labels=levels(BreastCancer.df$Class))
table(ans,BreastCancer.df$Class)
```

```{r}
#03. Model using random forest x bagging
require(party)
x.cf <- cforest(Class ~ ., data=train.df, control = cforest_unbiased(mtry = 9)) #?cforest_unbiased, bagging? #500 trees

x.cf.pred <- predict(x.cf, newdata=valid.df)
x.cf.prob <-  1- unlist(treeresponse(x.cf, valid.df), use.names=F)[seq(1,nrow(valid.df)*2,2)]
table(x.cf.pred,valid.df$Class) 
```

```{r}
#04. Model using SVM
require(e1071)
# svm requires tuning
x.svm.tune <- tune(svm, Class~., data = train.df,
                   ranges =list(gamma = 2^(-8:1), cost = 2^(0:4)),
                   tunecontrol = tune.control(sampling = "fix")) 
# display the tuning results (in text format)
x.svm.tune

# If the tuning results are on the margin of the parameters (e.g., gamma = 2^-8),
# then widen the parameters.
# manually copied the cost and gamma from console messages above to parameters below.
x.svm <- svm(Class~., data = train.df, cost=1, gamma=0.03125, probability = TRUE) 

x.svm.pred <- predict(x.svm, type="class", newdata=valid.df) #ensemble; only give the class
x.svm.prob <- predict(x.svm, type="prob", newdata=valid.df, probability =TRUE) # has to include probability = TRUE while type="prob" is not needed
t <- attr(x.svm.prob, "probabilities") # only give the probabilities
table(x.svm.pred,valid.df$Class) 
```

```{r}
#05. Model using Naive Bayes Classification
library(klaR)
x.nb <- NaiveBayes(Class~., data = train.df)
x.nb.pred <- predict(x.nb,valid.df)$class  #ensemble
x.nb.prob <- predict(x.nb,valid.df)$posterior
table(x.nb.pred,valid.df$Class)
```

```{r}
#06. Model using neural net
library(nnet)
x.nnet <- nnet(Class ~ ., data = train.df, size=1)
x.nnet.pred <- as.factor(predict(x.nnet, newdata=valid.df ,type="class"))
table(x.nnet.pred,valid.df$Class)

```

```{r}
#07. MOdel using regularised Discriminant Analysis
library(klaR)
x.rda <- rda(Class ~ ., data=train.df)
x.rda.pred <- predict(x.rda, newdata=valid.df)
table(x.rda.pred$class,valid.df$Class)

```



####Evaluation Phase####
#Plot ROC curves to compare the performance of the individual classifiers

```{r}
# Output the plot to a PNG file for display on web.
#png(filename="roc_curve_5_models.png", width=700, height=700)

# load the ROCR package 
require(ROCR)

# Create an ROCR curve from rpart() probabilities
x.rp.prob.rocr <- prediction(x.rp.prob[,2], valid.df$Class)
x.rp.perf <- performance(x.rp.prob.rocr, "tpr","fpr")
#plot(x.rp.perf, col=2, main="ROC curves comparing classification performance of five machine learning models")

# ROCR curve for cforest
x.cf.prob.rocr <- prediction(x.cf.prob, valid.df$Class)
x.cf.perf <- performance(x.cf.prob.rocr, "tpr","fpr")
#plot(x.cf.perf, col=4, add=TRUE)

#ROCR curve for SVM
x.svm.prob.rocr <- prediction(attr(x.svm.prob, "probabilities")[,2], valid.df$Class)
x.svm.perf <- performance(x.svm.prob.rocr, "tpr","fpr")
#plot(x.svm.perf, col=6, add=TRUE)

# Draw a legend.
#legend(0.6, 0.6, c('rpart', 'ctree', 'cforest','bagging','svm'), 2:6)

# Close and save the PNG file.
#dev.off()
```


####Deployment Phase####
#Combine the models into the ensemble and make a final prediction 

```{r}
#Combine predictions from models into a single dataframe
predictions.df <- as.data.frame(cbind(x.rp.pred, x.cf.pred, x.svm.pred, x.nb.pred, x.nnet.pred))

#Replace all 1's with 0's and then all 2's with 1's. This will allow quick summing of the rows to determine the majority vote for each observation in the validation set
predictions.df[predictions.df==1] <- 0 
predictions.df[predictions.df==2] <- 1 

#Sum each row to determine majority vote. Each 1 is a prediction for Malignant and each 0 is a prediction for Benign. Therefore, for each row with a sum of 3 or more indicates that the majority of our models predict the observation will be Malignant. Any row with a sum of 2 or less indicates that the majority of our models predict the observation will be Benign. 
majority <- as.factor(rowSums(predictions.df))
predictions.df$Majority <- majority
predictions.df$Majority_Class = ifelse(as.numeric(predictions.df$Majority)>=3,"Malignant","Benign")
  
```



